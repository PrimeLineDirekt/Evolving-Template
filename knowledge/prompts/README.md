---
title: "Prompt Library - High-Performance Prompt Patterns"
type: library-index
category: prompt-engineering
tags: [prompts, patterns, best-practices, inspiration, reusable]
created: 2024-11-22
status: active-collection
---

# Prompt Library - High-Performance Prompt Patterns

**Kuratierte Sammlung hocheffizienter, production-erprobter Prompts als Inspiration und Muster f√ºr zuk√ºnftige Projekte**

## Zweck dieser Sammlung

Diese Prompt Library ist **keine Code-Bibliothek zum direkten Copy-Paste**, sondern eine **Inspirationsquelle und Lern-Ressource** f√ºr effektives Prompt Engineering.

### Was du hier findest:
‚úÖ **Production-Ready Prompts** - Alle Prompts sind in echten Projekten erprobt
‚úÖ **Best Practices** - Patterns die nachweislich funktionieren
‚úÖ **Strukturierungs-Vorlagen** - Wie man Prompts aufbaut
‚úÖ **Domain-Expertise** - Wie man Fach-Autorit√§t etabliert
‚úÖ **Multi-Agent Patterns** - Koordination mehrerer Agents

### Was du NICHT hier findest:
‚ùå Fertige Prompts zum 1:1 √úbernehmen ohne Anpassung
‚ùå Generische "One-Size-Fits-All" Templates
‚ùå Ungetestete experimentelle Ans√§tze

## Philosophie: Learn, Adapt, Create

**Der richtige Workflow:**

1. **Learn** - Studiere die Patterns, verstehe die Struktur
2. **Adapt** - Passe an deine Domain und Use Case an
3. **Create** - Erstelle deinen eigenen, optimierten Prompt

**Nicht:** Copy-Paste ohne Verst√§ndnis ‚Üí Wird nicht funktionieren!

## Kategorien

### üìö Frameworks (`frameworks/`)
**Meta-Level Prompt Engineering Systeme**

Prompts die **andere Prompts erstellen** oder **Prompt-Engineering-Prozesse** definieren.

**Aktuell:**
1. **Prompt Pro 2.0** - 5-Level Hierarchie, Claude-optimiert, XML-Struktur
   - Use Case: Systematisch Prompts f√ºr verschiedene Aufgaben erstellen
   - Key Learning: Hierarchische Technique Selection, Performance Trade-offs
   - Confidence: 95%

2. **Idea Forge** - Adaptives Ideenentwicklungssystem
   - Use Case: Systematische Ideenentwicklung durch iterative Expertenanalyse
   - Key Learning: Divergence ‚Üí Convergence ‚Üí Roadmap Process
   - Confidence: 90%

**Wann verwenden:**
- Du brauchst einen strukturierten Prozess f√ºr Prompt-Erstellung
- Du willst Ideen systematisch entwickeln und validieren
- Du entwickelst mehrere Prompts und brauchst Konsistenz

### üî¨ Research Agents (`research-agents/`)
**Spezialisierte Research & Data Collection Prompts**

Prompts f√ºr **tiefe Recherche**, **Daten-Aggregation** und **Multi-Source Validation**.

**Aktuell:**
- **Research Orchestrator** - Multi-Domain E-Commerce Optimization
  - Use Case: E-Commerce SEO Research mit Confidence Scoring
  - Key Learning: Multi-Domain Workflows, Source Validation, Structured Output

**Wann verwenden:**
- Du brauchst strukturierte Research-Workflows
- Du musst Daten aus mehreren Quellen validieren
- Du willst Confidence Scores f√ºr Research-Ergebnisse

### üé≠ Pattern Library (`patterns/`)
**Production-Proven Agent Prompts aus echten Projekten**

Spezialisierte Agent-Prompts die in **Production-Systemen** laufen.

**Aktuell:**
_Keine Patterns im Template. F√ºge deine eigenen hinzu via /inbox-process._

**Wann verwenden:**
- Du entwickelst Multi-Agent Systeme
- Du brauchst Inspiration f√ºr spezialisierte Agents
- Du willst verstehen wie Production-Agents strukturiert sind

### üõ†Ô∏è Skills (`skills/`)
**Spezialisierte Workflow Prompts**

Wiederverwendbare Prompts f√ºr konkrete, wiederkehrende Workflows.

**Aktuell:**
_Keine Skills im Template. F√ºge deine eigenen hinzu via /inbox-process._

**Wann verwenden:**
- Du hast einen spezifischen, wiederholbaren Workflow
- Du brauchst domain-spezifische Automation
- Du willst production-ready Tools nutzen

## Wie du diese Library verwendest

### F√ºr neue Projekte

**Schritt 1: Identifiziere deine Anforderung**
- Brauchst du einen Meta-Prozess? ‚Üí `frameworks/`
- Brauchst du Research-Workflows? ‚Üí `research-agents/`
- Brauchst du spezialisierte Agents? ‚Üí `patterns/`

**Schritt 2: Studiere relevante Prompts**
- Lies den kompletten Prompt
- Achte auf Struktur und Patterns
- Verstehe WHY bestimmte Formulierungen gew√§hlt wurden

**Schritt 3: Extrahiere Patterns**
```
Beispiel aus profil-analyse.md:

STRUKTUR-PATTERN:
- Identity Establishment ("Du bist...")
- Core Capabilities (Bulletpoints)
- Input Specification (Was bekommst du)
- Output Format (Strukturierte Sections)
- Quality Criteria (Self-Validation)

‚Üí √úbertrage auf deine Domain!
```

**Schritt 4: Adaptiere f√ºr deinen Use Case**
- Ersetze Domain-Expertise mit deiner Expertise
- Passe Output-Formate an deine Bed√ºrfnisse an
- Behalte bew√§hrte Strukturen bei

**Schritt 5: Teste und Iteriere**
- Starte mit adaptiertem Prompt
- Teste mit echten Use Cases
- Verfeinere basierend auf Ergebnissen

### F√ºr Prompt Engineering Learning

**Studiere diese Aspekte:**

1. **Tone & Authority**
   - Wie wird Expertise etabliert?
   - Welche Sprache schafft Autorit√§t?
   - Wie wird Domain-Knowledge vermittelt?

2. **Strukturierung**
   - Wie sind Prompts aufgebaut?
   - Welche Sections gibt es?
   - Warum diese Reihenfolge?

3. **Output Control**
   - Wie werden strukturierte Outputs erzwungen?
   - Welche Formate funktionieren?
   - Wie wird Konsistenz sichergestellt?

4. **Quality Gates**
   - Wie validieren Prompts sich selbst?
   - Welche Kriterien werden verwendet?
   - Wie wird schlechter Output verhindert?

5. **Context Management**
   - Wie wird verf√ºgbarer Kontext genutzt?
   - Wie werden Dependencies dokumentiert?
   - Wie wird Cross-Agent Koordination erm√∂glicht?

## Best Practices aus dieser Library

### ‚úÖ DO's (aus allen Prompts extrahiert)

**1. Klare Identit√§t etablieren**
```markdown
GOOD: "Du bist ein Senior Tax Advisor mit 20+ Jahren Erfahrung in internationaler Steuerplanung..."
BAD:  "Du bist ein Berater."
```

**2. Strukturierte Outputs fordern**
```markdown
GOOD:
AUSGABE-FORMAT:
1. EXECUTIVE SUMMARY (200 W√∂rter)
2. DETAILLIERTE ANALYSE
3. ACTION ITEMS (Priorisiert)

BAD: "Erstelle eine Analyse."
```

**3. Domain-Language verwenden**
```markdown
GOOD: "Analysiere ¬ß6 AStG Wegzugsbesteuerung, DBA-Implikationen..."
BAD:  "Schau dir Steuergesetze an."
```

**4. Quality Criteria einbauen**
```markdown
GOOD:
QUALIT√ÑTS-CHECKS:
‚úì Alle kritischen Punkte adressiert
‚úì Keine Widerspr√ºche
‚úì Mindestens 3 konkrete Action Items

BAD: (keine Quality Gates)
```

**5. Kontext explizit machen**
```markdown
GOOD:
INPUT: 126-Felder User-Profil mit [spezifische Felder]
DEPENDENCIES: Nutze Output von [other_agent]

BAD: (implizite Annahmen)
```

### ‚ùå DON'Ts (zu vermeiden)

1. **Vage Instruktionen** - "Analysiere die Situation" (zu unspezifisch)
2. **Fehlende Struktur** - Unstrukturierte Outputs sind nicht aggregierbar
3. **Zu generisch** - "Sei ein Experte" (welche Art Experte?)
4. **Ignorieren von Edge Cases** - "Falls Daten fehlen..." muss adressiert werden
5. **Keine Self-Validation** - Ungepr√ºfte Outputs = schlechte Qualit√§t

## Verwendungs-Matrix

| Use Case | Empfohlene Prompts | Key Learning |
|----------|-------------------|--------------|
| Prompt-Erstellung systematisieren | Prompt Pro 2.0 | Technique Hierarchy, Performance Trade-offs |
| Ideenentwicklung | Idea Forge | Divergence ‚Üí Convergence ‚Üí Roadmap Process |
| Research-Workflows | Research Orchestrator | Multi-Domain Workflows, Confidence Scoring |

## Qualit√§ts-Standards

**Alle Prompts in dieser Library erf√ºllen:**

‚úÖ **Production-Proven** - Mindestens in einem echten Projekt eingesetzt
‚úÖ **Documented** - Kontext, Use Case, Key Learnings dokumentiert
‚úÖ **Structured** - Klare Sections, konsistente Formate
‚úÖ **Domain-Specific** - Echte Fach-Expertise, nicht generisch
‚úÖ **Quality-Controlled** - Self-Validation Mechanismen eingebaut

**Confidence Levels:**
- ‚≠ê‚≠ê‚≠ê 95%+ - Battle-tested, mehrere Monate Production
- ‚≠ê‚≠ê 85-94% - Proven in Production, k√ºrzere Laufzeit
- ‚≠ê 75-84% - Tested, noch in Optimierung

## Beitr√§ge zu dieser Library

**Wenn du einen Prompt hinzuf√ºgen m√∂chtest:**

1. **Production-Ready**: Muss in echtem Projekt verwendet worden sein
2. **Dokumentiert**: Frontmatter mit Use Case, Tags, Confidence
3. **Strukturiert**: Konsistente Sections, klare Formate
4. **Lern-Wert**: Muss spezifische Patterns demonstrieren
5. **Kein Duplicate**: Nicht redundant zu existierenden Prompts

**Kategorien-Auswahl:**
- `frameworks/` - Meta-Level Prompt Engineering
- `research-agents/` - Research & Data Collection
- `patterns/` - Spezialisierte Production Agents
- (Neue Kategorien nach Bedarf)

## Weiterf√ºhrende Ressourcen

**Projekt-Kontext:**
_Deine Projekte werden hier erscheinen, nachdem du sie mit /project-add hinzuf√ºgst._

**Externe Ressourcen:**
- Anthropic Prompt Engineering Guide
- Claude Best Practices

## Statistiken

**Aktuelle Library:**
- **3 Production-Ready Prompts**
- **3 Kategorien** (Frameworks, Research Agents, Skills)
- **Confidence**: 90-95% average across all prompts

**Kategorien-Verteilung:**
- Frameworks: 2 (Prompt Pro 2.0, Idea Forge)
- Research Agents: 1 (Research Orchestrator)
- Skills: 0
- Patterns: 0

**Letzte Aktualisierung:** 2024-11-22

---

**Prompt Library v1.0**
*Learn, Adapt, Create - Production-Proven Prompt Patterns f√ºr AI-Assisted Development*

**Knowledge Base**: [‚Üê Back to Index](../index.md)
