# /learning-review

Review system learning, accuracy metrics, and model performance.

## Model: sonnet

## Workflow

1. Load last 30 days of predictions
2. Compare predicted vs actual
3. Calculate accuracy metrics
4. Analyze errors (root cause)
5. Review experience memory entries
6. Show model refinements made
7. Output: Learning dashboard

## Output Format

```
## Learning System Review

### Prediction Accuracy (Last 30 Days)
- Total Predictions: 30
- Within 5%: 68% (20/30)
- Within 10%: 87% (26/30)
- Directional Accuracy: 77% (23/30)

**Overall Score**: 71.3%

### Accuracy Trend
- Last Week: 73%
- 2 Weeks Ago: 68%
- 4 Weeks Ago: 65%
→ Trending UP ✓ (self-improvement working)

### Recent Errors Analysis

**Error 1**: CPI Forecast -4.2%
- Root Cause: Fed pivot underestimated
- Learning: Add banking stress indicator
- Impact: Next forecast +8% better

**Error 2**: BTC Forecast -2.1%
- Root Cause: SEC news not captured
- Learning: Increase SEC monitor weight
- Impact: News response +15% faster

### Experience Memory Updates
- Solutions stored: 2 (Fed pivot, SEC impact)
- Patterns validated: 3 (election cycle, CPI lag, sentiment)
- Model adjustments: 2 (weights increased)

### Model Refinements Made
1. Fed Pivot Detection: Improved 15%
2. CPI Lag Weighting: +20% impact
3. SEC News Response: +12% speed

### Backtesting Performance
- 90-Day Backtest: 71.2% accuracy
- Sharpe Ratio: 1.47 (good risk-adjusted)
- Worst Error: -18% (black swan event)
- Best Forecast: +24% (bull case + more)

### Recommendations
- System performing well, trends improving
- Continue current tuning strategy
- Monitor: Banking stress indicator development
- Next optimization: Geopolitical sentiment extraction
```

## Usage

```
/learning-review
/learning-review detailed
/learning-review last-7-days
/learning-review accuracy-trend
```

## Plain Text Trigger

- "Zeige Lernfortschritt"
- "Wie gut funktioniert das System?"
- "Genauigkeit?"
- "Modellverbesserungen?"
